\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{vstrumbelj2014explaining,datta2016}
\citation{NIPS2017_7062}
\HyPL@Entry{0<</S/D>>}
\newlabel{sec:shapley}{{2}{1}{}{section.2}{}}
\newlabel{sec:shapley@cref}{{[section][2][]2}{[1][1][]1}}
\newlabel{eq:contrib}{{1}{1}{}{equation.2.1}{}}
\newlabel{eq:contrib@cref}{{[equation][1][]1}{[1][1][]1}}
\citation{shapley1953value}
\citation{pawlowskymodeling}
\citation{aitchison1982}
\citation{aitchison2001}
\citation{egozcue2003isometric}
\newlabel{eq:valuefunction}{{2}{2}{}{equation.2.2}{}}
\newlabel{eq:valuefunction@cref}{{[equation][2][]2}{[1][1][]2}}
\newlabel{sec:ilr}{{3.2}{2}{}{subsection.3.2}{}}
\newlabel{sec:ilr@cref}{{[subsection][2][3]3.2}{[1][2][]2}}
\citation{pawlowskymodeling}
\newlabel{eq:valuefunctionsimplex}{{5}{3}{}{equation.4.5}{}}
\newlabel{eq:valuefunctionsimplex@cref}{{[equation][5][]5}{[1][3][]3}}
\newlabel{sec:explain}{{5}{3}{}{section.5}{}}
\newlabel{sec:explain@cref}{{[section][5][]5}{[1][3][]3}}
\citation{pedregosa2011scikit}
\citation{egozcue2003isometric,egozcue2005groups,pawlowskymodeling}
\citation{pawlowskymodeling}
\newlabel{sec:balances}{{5.2}{4}{}{subsection.5.2}{}}
\newlabel{sec:balances@cref}{{[subsection][2][5]5.2}{[1][4][]4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:3classesshap}{{1a}{4}{Shapley compositions in the ILR space.\relax }{figure.caption.1}{}}
\newlabel{fig:3classesshap@cref}{{[subfigure][1][1]1a}{[1][3][]4}}
\newlabel{sub@fig:3classesshap}{{a}{4}{Shapley compositions in the ILR space.\relax }{figure.caption.1}{}}
\newlabel{sub@fig:3classesshap@cref}{{[subfigure][1][1]1a}{[1][3][]4}}
\newlabel{fig:3classesshapsum}{{1b}{4}{Sum of the Shapley compositions in the ILR space from the base to the prediction.\relax }{figure.caption.1}{}}
\newlabel{fig:3classesshapsum@cref}{{[subfigure][2][1]1b}{[1][3][]4}}
\newlabel{sub@fig:3classesshapsum}{{b}{4}{Sum of the Shapley compositions in the ILR space from the base to the prediction.\relax }{figure.caption.1}{}}
\newlabel{sub@fig:3classesshapsum@cref}{{[subfigure][2][1]1b}{[1][3][]4}}
\newlabel{fig:3classes}{{1}{4}{Shapley explaination in the ILR space for the classification of an Iris instance.\relax }{figure.caption.1}{}}
\newlabel{fig:3classes@cref}{{[figure][1][]1}{[1][3][]4}}
\citation{egozcue2003isometric}
\citation{egozcue2005groups}
\citation{aitchison1980}
\citation{egozcue2003isometric}
\citation{egozcue2003isometric}
\citation{pawlowskymodeling}
\newlabel{fig:4classesshapsum}{{2}{5}{Shapley explaination in the $3$-dimensional ILR space for a four classes digit recognition task. The Shapley compositions are summed in the ILR space from the base distribution to the prediction.\relax }{figure.caption.2}{}}
\newlabel{fig:4classesshapsum@cref}{{[figure][2][]2}{[1][4][]5}}
\citation{vstrumbelj2014explaining}
\citation{NIPS2017_7062}
\newlabel{fig:bifurc1}{{3a}{6}{Bifurcation tree corresponding to the basis obtained with the Gram-Schmidt procedure as in \cite {egozcue2003isometric} and used in the examples of Figures \ref {fig:3classes} and \ref {fig:4classesshapsum}.\relax }{figure.caption.3}{}}
\newlabel{fig:bifurc1@cref}{{[subfigure][1][3]3a}{[1][5][]6}}
\newlabel{sub@fig:bifurc1}{{a}{6}{Bifurcation tree corresponding to the basis obtained with the Gram-Schmidt procedure as in \cite {egozcue2003isometric} and used in the examples of Figures \ref {fig:3classes} and \ref {fig:4classesshapsum}.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:bifurc1@cref}{{[subfigure][1][3]3a}{[1][5][]6}}
\newlabel{fig:bifurc2}{{3b}{6}{Bifurcation tree used in our $10$-classes digit recognition task\relax }{figure.caption.3}{}}
\newlabel{fig:bifurc2@cref}{{[subfigure][2][3]3b}{[1][5][]6}}
\newlabel{sub@fig:bifurc2}{{b}{6}{Bifurcation tree used in our $10$-classes digit recognition task\relax }{figure.caption.3}{}}
\newlabel{sub@fig:bifurc2@cref}{{[subfigure][2][3]3b}{[1][5][]6}}
\newlabel{fig:trees}{{3}{6}{Two examples of bifurcation tree.\relax }{figure.caption.3}{}}
\newlabel{fig:trees@cref}{{[figure][3][]3}{[1][5][]6}}
\newlabel{fig:moreclasses35}{{4}{6}{Sum of the Shapley compositions from the base to the prediction in the ILR subspace made of $\tilde {p}_3$ and $\tilde {p}_5$.\relax }{figure.caption.4}{}}
\newlabel{fig:moreclasses35@cref}{{[figure][4][]4}{[1][5][]6}}
\newlabel{fig:histiris}{{5}{6}{Shapley compositions visualized as histograms for the Iris classification example.\relax }{figure.caption.5}{}}
\newlabel{fig:histiris@cref}{{[figure][5][]5}{[1][6][]6}}
\citation{langley00}
\bibdata{biblio}
\bibcite{aitchison1982}{{1}{1982}{{Aitchison}}{{}}}
\bibcite{aitchison2001}{{2}{2001}{{Aitchison}}{{}}}
\bibcite{aitchison1980}{{3}{1980}{{Aitchison \& Shen}}{{Aitchison and Shen}}}
\bibcite{datta2016}{{4}{2016}{{Datta et~al.}}{{Datta, Sen, and Zick}}}
\bibcite{egozcue2005groups}{{5}{2005}{{Egozcue \& Pawlowsky-Glahn}}{{Egozcue and Pawlowsky-Glahn}}}
\bibcite{egozcue2003isometric}{{6}{2003}{{Egozcue et~al.}}{{Egozcue, Pawlowsky-Glahn, Mateu-Figueras, and Barcelo-Vidal}}}
\bibcite{NIPS2017_7062}{{7}{2017}{{Lundberg \& Lee}}{{Lundberg and Lee}}}
\bibcite{pawlowskymodeling}{{8}{2015}{{Pawlowsky-Glahn et~al.}}{{Pawlowsky-Glahn, Egozcue, and Tolosana-Delgado}}}
\bibcite{pedregosa2011scikit}{{9}{2011}{{Pedregosa et~al.}}{{Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, et~al.}}}
\bibcite{shapley1953value}{{10}{1953}{{Shapley et~al.}}{{}}}
\bibcite{vstrumbelj2014explaining}{{11}{2014}{{{\v {S}}trumbelj \& Kononenko}}{{{\v {S}}trumbelj and Kononenko}}}
\bibstyle{icml2024}
\newlabel{fig:histiris}{{6}{7}{Shapley compositions visualized as histograms for the seven classes digit recognition example.\relax }{figure.caption.6}{}}
\newlabel{fig:histiris@cref}{{[figure][6][]6}{[1][6][]7}}
\newlabel{app:properties}{{A}{8}{}{appendix.A}{}}
\newlabel{app:properties@cref}{{[appendix][1][2147483647]A}{[1][8][]8}}
\newlabel{eq:linearsimplex}{{8}{8}{}{equation.A.8}{}}
\newlabel{eq:linearsimplex@cref}{{[equation][8][2147483647]8}{[1][8][]8}}
\newlabel{tab:normiris}{{1}{11}{Norm of the Shapley compositions, projection on the class-compositions and cosine similarity betweeen the Shapley compositions for the Iris classification example.\relax }{table.caption.8}{}}
\newlabel{tab:normiris@cref}{{[table][1][2147483647]1}{[1][11][]11}}
\newlabel{tab:normiris}{{2}{11}{Norm of the Shapley compositions and Cosine similarity betweeen the Shapley compositions for the $10$-classes digit recognition example.\relax }{table.caption.9}{}}
\newlabel{tab:normiris@cref}{{[table][2][2147483647]2}{[1][11][]11}}
\newlabel{app:summarize}{{C}{11}{}{appendix.C}{}}
\newlabel{app:summarize@cref}{{[appendix][3][2147483647]C}{[1][11][]11}}
\newlabel{tab:normiris}{{3}{11}{Projection of the Shapley compositions on the class-compositions for the $10$-classes digit recognition example.\relax }{table.caption.10}{}}
\newlabel{tab:normiris@cref}{{[table][3][2147483647]3}{[1][11][]11}}
\citation{vstrumbelj2014explaining}
\citation{vstrumbelj2014explaining}
\citation{vstrumbelj2014explaining}
\citation{vstrumbelj2014explaining}
\citation{vstrumbelj2014explaining}
\citation{vstrumbelj2014explaining}
\newlabel{app:algo}{{D}{12}{}{appendix.D}{}}
\newlabel{app:algo@cref}{{[appendix][4][2147483647]D}{[1][12][]12}}
\newlabel{alg:1}{{1}{12}{Adaptation of the Algorithm 1 in \cite {vstrumbelj2014explaining} for approximating the Shapley composition of the $i$th feature, with model $\bm {f}$, instance $\bm {x}\in \mathcal {X}$ and $m$ drawn samples.\relax }{algorithm.1}{}}
\newlabel{alg:1@cref}{{[algorithm][1][2147483647]1}{[1][12][]12}}
\citation{NIPS2017_7062}
\newlabel{alg:2}{{2}{13}{Adaptation of the Algorithm 2 in \cite {vstrumbelj2014explaining} for approximating all the Shapley compositions by optimally distributing a maximum number of samples $m_{\text {max}}$ over the $d$ features, with model $\bm {f}$, instance $\bm {x}\in \mathcal {X}$ and $m_{\text {min}}$ the minimum number of samples each feature estimation.\relax }{algorithm.2}{}}
\newlabel{alg:2@cref}{{[algorithm][2][2147483647]2}{[1][12][]13}}
\newlabel{app:correct}{{E}{13}{}{appendix.E}{}}
\newlabel{app:correct@cref}{{[appendix][5][2147483647]E}{[1][13][]13}}
\gdef \@abspage@last{14}
